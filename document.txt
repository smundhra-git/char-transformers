i will be documenting my work. Let's see how far i get. 

first what i am working on - 
I read this paper : https://arxiv.org/pdf/1706.03762 and now I am feeling like a good developer so I plan to write an entire transformer model, lets see how this macho'sm plays out.


Also I am talking to GPT on the side to breakdown the ideas i have in my head to actionable tasks (secret sauce - it works)

Okay coming back to what I am doing exactly -
I am gonna use text, possibly Shakespeare or my own code or any other text and make it predict the next character 

Let's start from 1st phase -
I will input a long stream of data (text) and then map each character to a number since our model will be using that. 

e.g. could be 'a' will be 1 and 'b' 2 and so on, and then 'A' could be 27 ...

As a weird guy, I am not using cursor right now

data/raw.txt will have the data
now i will make the Matrix, yes i am not using Eigen - keeping it as lightweight as possible and i like speed so we use C++.

In math/Matrix we will build a type matrix with dimensions

We will implement a constructor, indexing i, j = like vectors
basic sanity checks and a matmul function 

This is very basic - i have written the constructor, an access element at (row, col)
i am deciding if i want to have a conveience operator like () to call a position - i am gonna avoid it for right now. may come back later

 i have written the header file for matrix - after implementing the function i will write a Cmakefile and then eat food - feeling mexican

I am finished implementing the matrix functions and like any good developer i would test it now - you know where? In main.cpp

for cpmpilation use - g++ -std=c++17 -I./src -o main src/main.cpp src/math/matrix.cpp


I am happy to see this - 
" ./main 
=== Matrix tests start ===
Constructor / zeros / constant / fill tests passed.
add / subtract / hadamard / scalar_mul tests passed.
matmul test passed.
transpose test passed.
row_softmax tests passed.
Example matrix A:
1 2 3 
4 5 6 
=== All Matrix tests passed successfully ===
"

next we will move to phase 2 an autograd engine (Tensor + Graph) - after this our matrix will keep a track of operations and compute gradients

Alright i am back and i am gonna create the autograd engine now
Here is the design 
- We will create Tensor type that will wrap Matrix - and optionally track gradients, know which node created it (will be needed for backdrop)

- a node abstractipn representing operations in the graph- 
this will hold a reference to input tensors 
and will know how to compute gradients for inputs given gradients for outputs

- a backward(tensor& loss ) function that will start from scalar loss an walk the graph backward and fill in .grad for all parameters
this will let us do stupid but interesting things like this - 
Tensor x = Tension from matrix(A, requires a grad)
Tensor y = some operation(x, ...)
Tensor loss = mse_loss(y, target)
and loss.backward() to populare x.grad etc

now i am writing the skeleton for tensor.hpp

so i am writing it just for 2x2 right now, and given myself a TODO to expand it to N-dim. So i have made a basic skeleton for tensor and now it is time to rock node - it is interesting since i have to use a shareD_ptr<node> so i have forward declared it 

Stuf like this make me love C++ even more.

alright time ti write node's skeleton

Wrote it, later we will create a derived Node types for each of this 
- AddNode
- MatmulNode
-Relu Node and et cetra etc. 

Each derived class will store any extra info needed, and implement backward to computer gradients for the inputs

Till now this is very fun. now i am gonne implement Tensor - so i am gonna lock in for this - will write my thoughts after

I have made a stub for Tensor, Node and backward function 
first we have to design how the backprop will actaully walk the graph
implement our first differntiable op with is adding two tensors
wire the backward(loss) to call into ops' node::backward() function
and then write a test in main

before making this changes, one important thing - right now my node has a v<Tensor*> inputs and a backward() function - that means to call node->backward(), backward(loss) needs to know the grad_output but the grdaient of a node is always stored in the tensors grad object
so it will be simpler if each node has a output to its output tensor and its backward() reads output>grad internally
so first i will tweak the node a lil bit

now i will write the App for Tensors in engines/ops and here later we will have matmul, relu etc
this ops will sit between math (pure numeric) and engine(autograd)

now important notes - const_cast<Tensor*> is used because inputs will be passed as const Tensor& but we will need to mutate .grad - this is a common design for autograd - we rely that the user will not modify the data via non-const ops
we also ensutre that only tensors with requires_grad = true are updated

now we will implement the real backward(Tensor& loss) graph traversal
- currently we have tensors with .grad_fn and nodes with input,ouput and backward()
we need a topological order of this nodes from the loss (downwards)
then traverse them in reverse and continuosly propogate the gradients 

so easiest thing which comes to mind directly here is DFS from loss.grad_fn to collect all the reachable nodes, sotre them in a vector post-order - reverse the vector and we can get the backprop order

so i just wrote the DFS, remembered my competitve programming days - it took me less than 40 secs to write it

well now i have also implemented the sum feautes and the main is now tests for that. 
the next steps will be to implement more ops like matmul, elementwise nonlibearity (relu) etc
and build a small MLP on top

now sinec we have a baby autograd engine 
we will make a neural network primitive at the Tensor level - what this means to common people like us is we will write the matmul function at node level and an activation function, also a simple loss

well i have implemented relu and matmul, also during this time i read a paper
- https://pmc.ncbi.nlm.nih.gov/articles/PMC11142305/
good paper, i will beat the stats there


by the way tested my relu, matmul and loss and guess what? i got a seegmentation fault error

Thought - "He cut his hand" is a sentence filled with linguistic ambuigity, if someday humankind cracks AGI what would it assume as most of the time, did A cut B hands or A cuts A hand?


the seg fault was insane, i was directly passing the output of matmul to relu - and not creating a variable to store it and hence it crashed

now we will work on the linear layer abstraction y=xW + b 
a basic loss + optimizer
and a tiny mlp sanity check 

I am starting with Linear now
theoritically this is what linear will do - for input batch x of shape [bs x if]:
y = xW + b 
W is [if*of]
b is [1xof] and y is [bs * of]
bs is batch size, if is in features and of is guess what? out fesutres. 

well i locked in and implemented the Linear implementation, one hting which you may face too is if you have a node which you wil ldestruct future do nto keep it as a ref to another node or else the program will crash 

now we will add a mse_loss op and a tiny SGD optimizer, wire a 2 layer MLP (on say XOR) and run a end-to-end test

Writing the MSE was not fun (not if you have notices the trend that the information repeats itself in the node extensions now) so it is a lot of not thinking jsut doing now. 

also another interesting paper i read last night was - https://arxiv.org/pdf/2506.12220. Yes there are some flaws in the paper and i have informed the authors, i hop they improve them

And now getting back to writing the optimizer or the sgd 

so i have made the header file and this shall be very simple to implement 

one thing i have to do is ensure that i do not keep accessing deleted memory, get seg fault error and then fix - it is wasting my time

amazingly the optimizer worked in a single time and now i am gonna build a char-level transformer on top of this engine (embedding -> multi head attention -> MLP -> output head) and later i will evolve this into a medical reasoning transformer.

before that I tried to tweak the test to XOR and it didn't really learn - interesting - have to tweak the mse 

=== 2-layer MLP on XOR (1-sample SGD) ===
Epoch 0  loss = 0.44023
Epoch 500  loss = 1.23689e-22
Epoch 1000  loss = 1.97215e-31
Epoch 1500  loss = 1.97215e-31
Epoch 2000  loss = 1.97215e-31
Epoch 2500  loss = 1.97215e-31
Epoch 3000  loss = 1.97215e-31
Epoch 3500  loss = 1.97215e-31
Epoch 4000  loss = 1.97215e-31
Epoch 4500  loss = 1.97215e-31

Final predictions:
(0, 0) -> 4.44089e-16 (target 0)
(0, 1) -> 1 (target 1)
(1, 0) -> 1 (target 1)
(1, 1) -> 3.9968e-16 (target 0)

this is the response i got. Isn't it beautiful? It is textbook XOR solve.

now i am gonna push this and then start working on data + encoding utilies, positional encoding modules and self attention blocks

first target we have is to make a tiny char-transfoemr spec 
few numbers we need to know 
the dimensions of the model is 64, number of heads is 4, layers is 2, block size will be 64 and vocab size would be whatever the text gives (i aim to start close to 100 chars)

now we will be dealing with strings, lets see how much solving strings question on leetcode will help me. refer to src/data for this

so i have implemented both vocab and datasets and am now wriing tests, after writing a bit you should always test

next step we will make a mebeddging layer design 
what embeddings will do - 
Param W with shape [vocab size * d model], requires_grad = true
input a vector<int> of token ids and output a tensor of shape [n*d_model] for each position p with id token_ids[p] = i we will accumulate as so 
dL/dWi += dL/Doutp - the node will store a copy of the ids inside itself to it does not scatter-add in backward

so i did that step and tested it and it is working awesonly 